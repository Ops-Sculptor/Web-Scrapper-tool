# ğŸ•µï¸â€â™‚ï¸ Web Scraper Tool

A modular and maintainable Python tool for scraping **visiting card information** from websites.  
It supports both **static scraping** (`requests` + BeautifulSoup) and **dynamic scraping** (Selenium), applies intelligent tagging, and outputs results in Excel or JSON.


## ğŸ“Œ Features
- **Category-based scraping** â€” Healthcare, IT, Legal, Finance, Real Estate, and more.
- **Multi-method scraping** â€” Static (Requests) and Dynamic (Selenium) for JavaScript-heavy pages.
- **Multiple extraction strategies** â€” JSON-LD, contact sections, category-specific selectors, and generic patterns.
- **Data cleaning & processing**:
  - Email & phone validation
  - Duplicate removal
  - Location-based tagging
- **Flexible output** â€” Save results to Excel (`.xlsx`) or JSON.
- **Customizable configuration** via `scraper_config.json`.

## ğŸ“‚ Project Structure
Web-Scraper-tool/
â”‚
â”œâ”€â”€ main.py # Entry point
â”œâ”€â”€ requirements.txt # Python dependencies
â”‚
â”œâ”€â”€ config/
â”‚ â”œâ”€â”€ scraper_config.json # User settings for categories, selectors, filters
â”‚ â””â”€â”€ config_loader.py # Config loader and saver
â”‚
â”œâ”€â”€ core/
â”‚ â”œâ”€â”€ models.py # VisitingCard dataclass
â”‚ â””â”€â”€ logger.py # Centralized logging setup
â”‚
â”œâ”€â”€ scraping/
â”‚ â”œâ”€â”€ base_scraper.py # HTTP session setup
â”‚ â”œâ”€â”€ requests_scraper.py # Static scraping logic
â”‚ â”œâ”€â”€ selenium_scraper.py # Dynamic scraping logic
â”‚ â”œâ”€â”€ extractors.py # HTML parsing & field extraction
â”‚ â”œâ”€â”€ pagination.py # Pagination handling
â”‚ â””â”€â”€ dynamic_loading.py # Infinite scroll/load-more handling
â”‚
â”œâ”€â”€ processing/
â”‚ â”œâ”€â”€ filters.py # Email/phone validation
â”‚ â”œâ”€â”€ tagging.py # Auto-tagging by location
â”‚ â””â”€â”€ deduplication.py # Duplicate removal
â”‚
â””â”€â”€ output/
â”œâ”€â”€ excel_writer.py # Save results to Excel
â””â”€â”€ json_writer.py # Save results to JSON
---

## âš™ï¸ Installation
### 1ï¸âƒ£ Clone the repository
git clone https://github.com/Ops-Sculptor/Web-Scrapper-tool.git
cd Web-Scrapper-tool
2ï¸âƒ£ Create & activate a virtual environment
python -m venv .venv
# Windows PowerShell
.\.venv\Scripts\activate
# macOS/Linux
source .venv/bin/activate
3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

ğŸš€ Usage
1ï¸âƒ£ Edit the configuration
Open config/scraper_config.json and set:
Categories & keywords to scrape
CSS selectors for extraction
Filters & validation rules
Selenium settings (headless mode, timeouts, etc.)
2ï¸âƒ£ Run the scraper
python main.py
3ï¸âƒ£ Output
Excel: output.xlsx
JSON: output.json
Logs: scraper.log

ğŸ›  Customization
Add new categories â†’ Edit scraper_config.json in config/
Change scraping method â†’ Toggle "use_selenium": true in config
Add more output formats â†’ Create new writer modules in output/

ğŸ“œ Requirements
Python 3.8+
Google Chrome + ChromeDriver (for Selenium)
Internet connection

ğŸ¤ Contributing
Fork this repo

Create a new branch:
git checkout -b feature/my-feature
Make changes

Commit and push:
git commit -m "feat: add my new feature"
git push origin feature/my-feature
Open a pull request

ğŸ“„ License
This project is licensed under the MIT License â€” see the LICENSE file for details.
