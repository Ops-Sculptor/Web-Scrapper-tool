# ğŸ•µï¸â€â™‚ï¸ Web Scraper Tool

A modular and maintainable Python tool for scraping **visiting card information** from websites.  
It supports both **static scraping** (`requests` + BeautifulSoup) and **dynamic scraping** (Selenium), applies intelligent tagging, and outputs results in Excel or JSON.

---

## ğŸ“Œ Features

- **Category-based scraping** â€” Healthcare, IT, Legal, Finance, Real Estate, and more.
- **Multi-method scraping** â€” Static (Requests) and Dynamic (Selenium) for JavaScript-heavy pages.
- **Multiple extraction strategies** â€” JSON-LD, contact sections, category-specific selectors, and generic patterns.
- **Data cleaning & processing**:
  - Email & phone validation
  - Duplicate removal
  - Location-based tagging
- **Flexible output** â€” Save results to Excel (`.xlsx`) or JSON.
- **Customizable configuration** via `scraper_config.json`.

---

## ğŸ“‚ Project Structure

Web-Scraper-tool/
â”‚
â”œâ”€â”€ main.py # Entry point
â”œâ”€â”€ requirements.txt # Python dependencies
â”‚
â”œâ”€â”€ config/
â”‚ â”œâ”€â”€ scraper_config.json # User settings for categories, selectors, filters
â”‚ â””â”€â”€ config_loader.py # Config loader and saver
â”‚
â”œâ”€â”€ core/
â”‚ â”œâ”€â”€ models.py # VisitingCard dataclass
â”‚ â””â”€â”€ logger.py # Centralized logging setup
â”‚
â”œâ”€â”€ scraping/
â”‚ â”œâ”€â”€ base_scraper.py # HTTP session setup
â”‚ â”œâ”€â”€ requests_scraper.py # Static scraping logic
â”‚ â”œâ”€â”€ selenium_scraper.py # Dynamic scraping logic
â”‚ â”œâ”€â”€ extractors.py # HTML parsing & field extraction
â”‚ â”œâ”€â”€ pagination.py # Pagination handling
â”‚ â””â”€â”€ dynamic_loading.py # Infinite scroll/load-more handling
â”‚
â”œâ”€â”€ processing/
â”‚ â”œâ”€â”€ filters.py # Email/phone validation
â”‚ â”œâ”€â”€ tagging.py # Auto-tagging by location
â”‚ â””â”€â”€ deduplication.py # Duplicate removal
â”‚
â””â”€â”€ output/
â”œâ”€â”€ excel_writer.py # Save results to Excel
â””â”€â”€ json_writer.py # Save results to JSON

yaml
Copy
Edit

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/Ops-Sculptor/Web-Scrapper-tool.git
cd Web-Scrapper-tool
2ï¸âƒ£ Create & activate a virtual environment
bash
Copy
Edit
python -m venv .venv

# Windows PowerShell
.\.venv\Scripts\activate

# macOS/Linux
source .venv/bin/activate
3ï¸âƒ£ Install dependencies
bash
Copy
Edit
pip install -r requirements.txt
ğŸš€ Usage
1ï¸âƒ£ Edit the configuration
Open config/scraper_config.json and set:

Categories & keywords to scrape

CSS selectors for extraction

Filters & validation rules

Selenium settings (headless mode, timeouts, etc.)

2ï¸âƒ£ Run the scraper
bash
Copy
Edit
python main.py
3ï¸âƒ£ Output
Excel: output.xlsx

JSON: output.json

Logs: scraper.log

ğŸ›  Customization
Add new categories â†’ Edit scraper_config.json in config/

Change scraping method â†’ Toggle "use_selenium": true in config

Add more output formats â†’ Create new writer modules in output/

ğŸ“œ Requirements
Python 3.8+

Google Chrome + ChromeDriver (for Selenium)

Internet connection

ğŸ¤ Contributing
Fork this repo

Create a new branch:

bash
Copy
Edit
git checkout -b feature/my-feature
Make changes

Commit and push:

bash
Copy
Edit
git commit -m "feat: add my new feature"
git push origin feature/my-feature
Open a pull request

ğŸ“„ License
This project is licensed under the MIT License â€” see the LICENSE file for details.

ğŸ“§ Contact
If you have questions or need help customizing this scraper, feel free to open an issue in the repository.

yaml
Copy
Edit

---

I kept it **professional but approachable**, added **code blocks** for commands, and explained the modular architecture so anyone can jump in.  

If you want, I can also add **example output screenshots** and **badges** (Python version, license, build status) so your GitHub page looks more polished. Would you like me to do that?
